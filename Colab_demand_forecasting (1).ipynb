{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b16b4074-b3cf-4966-9e93-8c868df2a53c",
      "metadata": {
        "id": "b16b4074-b3cf-4966-9e93-8c868df2a53c"
      },
      "source": [
        "# Business issue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a8b1c9-32fa-41a6-aa25-d5a230f00fbe",
      "metadata": {
        "id": "c0a8b1c9-32fa-41a6-aa25-d5a230f00fbe"
      },
      "source": [
        "H&M Group is a family of brands and businesses with 53 online markets and approximately 4,850 stores. Our online store offers shoppers an extensive selection of products to browse through. But with too many choices, customers might not quickly find what interests them or what they are looking for, and ultimately, they might not make a purchase. To enhance the shopping experience, product recommendations are key. More importantly, helping customers make the right choices also has a positive implications for sustainability, as it reduces returns, and thereby minimizes emissions from transportation.\n",
        "\n",
        "In this competition, H&M Group invites you to develop product recommendations based on data from previous transactions, as well as from customer and product meta data. The available meta data spans from simple data, such as garment type and customer age, to text data from product descriptions, to image data from garment images.\n",
        "\n",
        "There are no preconceptions on what information that may be useful â€“ that is for you to find out. If you want to investigate a categorical data type algorithm, or dive into NLP and image processing deep learning, that is up to you."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e937394-3a63-47c2-aaf4-7148b9ba15eb",
      "metadata": {
        "id": "9e937394-3a63-47c2-aaf4-7148b9ba15eb"
      },
      "source": [
        "# Business request"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc58c1e-a6e9-41cb-81ff-9458f5f523fd",
      "metadata": {
        "id": "bbc58c1e-a6e9-41cb-81ff-9458f5f523fd"
      },
      "source": [
        "For this challenge you are given the purchase history of customers across time, along with supporting metadata. Your challenge is to predict what articles each customer will purchase in the 7-day period immediately after the training data ends. Customer who did not make any purchase during that time are excluded from the scoring."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2762f73-bd63-4ec0-9602-d87a62d51cba",
      "metadata": {
        "id": "c2762f73-bd63-4ec0-9602-d87a62d51cba"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05fc5e49-e42d-472f-b9fc-5aefbd41f3aa",
      "metadata": {
        "id": "05fc5e49-e42d-472f-b9fc-5aefbd41f3aa"
      },
      "source": [
        "images/ - a folder of images corresponding to each article_id; images are placed in subfolders starting with the first three digits of the article_id; note, not all article_id values have a corresponding image."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05cd2b13-f941-4a7d-b884-1251e266670c",
      "metadata": {
        "id": "05cd2b13-f941-4a7d-b884-1251e266670c"
      },
      "source": [
        "articles.csv - detailed metadata for each article_id available for purchase"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e279febb-7003-45b3-91a2-4a6805240bd2",
      "metadata": {
        "id": "e279febb-7003-45b3-91a2-4a6805240bd2"
      },
      "source": [
        "customers.csv - metadata for each customer_id in dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6260c87-d4b9-4f27-b9fa-203b9c9cb0f2",
      "metadata": {
        "id": "e6260c87-d4b9-4f27-b9fa-203b9c9cb0f2"
      },
      "source": [
        "transactions_train.csv - the training data, consisting of the purchases each customer for each date, as well as additional information. Duplicate rows correspond to multiple purchases of the same item. Your task is to predict the article_ids each customer will purchase during the 7-day period immediately after the training data period.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LOJ5f0oE0h1K",
      "metadata": {
        "id": "LOJ5f0oE0h1K"
      },
      "source": [
        "# Mount G. drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gQ4RYgpQ0STR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ4RYgpQ0STR",
        "outputId": "d664a8ca-e27f-4a09-f300-b121f5b75097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "PlEaUFVc0d0P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlEaUFVc0d0P",
        "outputId": "c69a3868-0e19-43cd-eb1e-58ae2690754e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.26.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.15.4)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.2)\n",
            "created virtual environment CPython3.10.12.final.0-64 in 419ms\n",
            "  creator CPython3Posix(dest=/content/env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.2, setuptools==74.1.2, wheel==0.44.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!pip3.10 install virtualenv\n",
        "!virtualenv env\n",
        "!source /content/env/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0775e3-a033-41d5-86ae-75d002ecaba3",
      "metadata": {
        "id": "5a0775e3-a033-41d5-86ae-75d002ecaba3"
      },
      "source": [
        "# Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d84e0aba-69c5-408b-9ae2-8621706c8bd0",
      "metadata": {
        "id": "d84e0aba-69c5-408b-9ae2-8621706c8bd0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import datetime\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2ce6590-1a22-412b-aa02-e70aba998718",
      "metadata": {
        "id": "a2ce6590-1a22-412b-aa02-e70aba998718"
      },
      "outputs": [],
      "source": [
        "import missingno as msno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2b5a5a53-f009-4c9f-9ccb-f0f1737d21ac",
      "metadata": {
        "id": "2b5a5a53-f009-4c9f-9ccb-f0f1737d21ac"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4cf4262-77f4-4579-8224-8eca713c4b5a",
      "metadata": {
        "id": "a4cf4262-77f4-4579-8224-8eca713c4b5a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4afa21dc-ad89-4e9a-9e77-ef59bd284f07",
      "metadata": {
        "id": "4afa21dc-ad89-4e9a-9e77-ef59bd284f07"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from  torch.nn.functional import one_hot\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "94c5f690-45cc-4e7d-be3b-d538e8cca0bb",
      "metadata": {
        "id": "94c5f690-45cc-4e7d-be3b-d538e8cca0bb"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e53e79-3c68-433a-9ef9-96aa47692f8b",
      "metadata": {
        "id": "e9e53e79-3c68-433a-9ef9-96aa47692f8b"
      },
      "source": [
        "# Loading datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "288edb6f-4f5d-49e8-bfad-3f8be9c05adf",
      "metadata": {
        "id": "288edb6f-4f5d-49e8-bfad-3f8be9c05adf"
      },
      "source": [
        "## Paths and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dcac7738-e00c-4f38-b34d-5dde57c90259",
      "metadata": {
        "id": "dcac7738-e00c-4f38-b34d-5dde57c90259"
      },
      "outputs": [],
      "source": [
        "nrows = 8000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "687f5f19-ac00-440b-9444-fac8d04728aa",
      "metadata": {
        "id": "687f5f19-ac00-440b-9444-fac8d04728aa"
      },
      "outputs": [],
      "source": [
        "class Load():\n",
        "    def __init__(self, path, nrows=nrows):\n",
        "        self.path = path\n",
        "        self.nrows = nrows\n",
        "    def read(self):\n",
        "        df = pd.read_csv(self.path, sep=',', nrows=self.nrows)\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "GMUej9BZT3IT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUej9BZT3IT",
        "outputId": "1dd25721-6bd0-4c68-eea8-589a89728fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "13f126d4-0815-4a6a-b1a7-d834d16ea1cb",
      "metadata": {
        "id": "13f126d4-0815-4a6a-b1a7-d834d16ea1cb"
      },
      "outputs": [],
      "source": [
        "#path_cust = '/Users/olivierdebeyssac/Python_demand_forecasting/h_m_data/customers.csv'\n",
        "#path_art = '/Users/olivierdebeyssac/Python_demand_forecasting/h_m_data/articles.csv'\n",
        "#path_transac = '/Users/olivierdebeyssac/Python_demand_forecasting/h_m_data/transactions_train.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "VvikV-eG1aIH",
      "metadata": {
        "id": "VvikV-eG1aIH"
      },
      "outputs": [],
      "source": [
        "path_cust = '/content/drive/MyDrive/Colab Notebooks/Python_demand_forecasting/h_m_data/customers.csv'\n",
        "path_art = '/content/drive/MyDrive/Colab Notebooks/Python_demand_forecasting/h_m_data/articles.csv'\n",
        "path_transac = '/content/drive/MyDrive/Colab Notebooks/Python_demand_forecasting/h_m_data/transactions_train.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f208809-667c-48ee-a210-55c1d1a24e43",
      "metadata": {
        "id": "0f208809-667c-48ee-a210-55c1d1a24e43"
      },
      "source": [
        "## Customer data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b23ca008-bcd8-46c5-97eb-14d506125de3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "b23ca008-bcd8-46c5-97eb-14d506125de3",
        "outputId": "38371f3e-1b18-4d43-a958-65da92dee107"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-50a650582f09>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_cust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_cust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_cust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_cust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e78c06469fa5>\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1763\u001b[0m                 \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         return create_block_manager_from_column_arrays(\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[0;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m         \u001b[0mraise_construction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1748\u001b[0m         \u001b[0;31m#  BlockManager objects not yet attached to a DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m         merged_blocks, _ = _merge_blocks(\n\u001b[0m\u001b[1;32m   2218\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_block_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "data_cust = Load(path_cust)\n",
        "df_cust = data_cust.read()\n",
        "df_cust.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kSDrPFJu3gtV",
      "metadata": {
        "id": "kSDrPFJu3gtV"
      },
      "outputs": [],
      "source": [
        "df_cust.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51599996-7f9d-48a3-a916-ff0510bda39e",
      "metadata": {
        "id": "51599996-7f9d-48a3-a916-ff0510bda39e"
      },
      "outputs": [],
      "source": [
        "df_cust.isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36951b37-229f-4f04-9be0-1a93079a319d",
      "metadata": {
        "id": "36951b37-229f-4f04-9be0-1a93079a319d"
      },
      "outputs": [],
      "source": [
        "df_cust.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wNzjFO2Oo0jL",
      "metadata": {
        "id": "wNzjFO2Oo0jL"
      },
      "source": [
        "- We see high rate missing values for features:\n",
        "  - FN\n",
        "  - Active\n",
        "- We will treat missing values later in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0818e9c3-fab7-4621-95c5-59a4a499b95c",
      "metadata": {
        "id": "0818e9c3-fab7-4621-95c5-59a4a499b95c"
      },
      "source": [
        "## Articles data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68cbcf84-2dd9-4006-91a7-bd4034bacac5",
      "metadata": {
        "id": "68cbcf84-2dd9-4006-91a7-bd4034bacac5"
      },
      "outputs": [],
      "source": [
        "data_art = Load(path_art)\n",
        "df_art = data_art.read()\n",
        "df_art.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0581918b-e655-4512-b523-d456a52019c1",
      "metadata": {
        "id": "0581918b-e655-4512-b523-d456a52019c1"
      },
      "outputs": [],
      "source": [
        "df_art.isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72c6e1e-b5ce-4382-b459-802a0360377f",
      "metadata": {
        "id": "c72c6e1e-b5ce-4382-b459-802a0360377f"
      },
      "outputs": [],
      "source": [
        "df_art.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kthTSD4EpWC5",
      "metadata": {
        "id": "kthTSD4EpWC5"
      },
      "source": [
        "- df_art has no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e90c35c-932d-45be-b769-7695fa9521bc",
      "metadata": {
        "id": "5e90c35c-932d-45be-b769-7695fa9521bc"
      },
      "source": [
        "## Transaction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d39f07a-1578-4e79-ac96-bfcb6282c2bb",
      "metadata": {
        "id": "2d39f07a-1578-4e79-ac96-bfcb6282c2bb"
      },
      "outputs": [],
      "source": [
        "data_transac = Load(path_transac)\n",
        "df_transac = data_transac.read()\n",
        "df_transac.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f19cb2-30fb-4cec-b3d5-ea578eaa7017",
      "metadata": {
        "id": "76f19cb2-30fb-4cec-b3d5-ea578eaa7017"
      },
      "outputs": [],
      "source": [
        "df_transac.isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b551471c-dfae-4300-aab3-fef5f8232946",
      "metadata": {
        "id": "b551471c-dfae-4300-aab3-fef5f8232946"
      },
      "outputs": [],
      "source": [
        "df_transac.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UsldcGiPphY7",
      "metadata": {
        "id": "UsldcGiPphY7"
      },
      "source": [
        "- df_transac has no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6dccea2-9cd5-4eb1-8491-0515bba736ac",
      "metadata": {
        "id": "a6dccea2-9cd5-4eb1-8491-0515bba736ac"
      },
      "source": [
        "# Data visualisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5LtiP1-j5xI4",
      "metadata": {
        "id": "5LtiP1-j5xI4"
      },
      "outputs": [],
      "source": [
        "age_min = df_cust['age'].min()\n",
        "age_med = df_cust['age'].median()\n",
        "age_max = df_cust['age'].max()\n",
        "print('age min: {}, age_med: {}, age max: {}'.format(age_min, age_med, age_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uEej1e1Ue7jv",
      "metadata": {
        "id": "uEej1e1Ue7jv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Histogram of age\n",
        "\"\"\"\n",
        "\n",
        "fig = px.histogram(df_cust['age'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acx4vt5yhtCE",
      "metadata": {
        "id": "acx4vt5yhtCE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "data distribution of age\n",
        "\"\"\"\n",
        "\n",
        "fig = px.box(df_cust, x=\"age\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j9hHQcrXqaGT",
      "metadata": {
        "id": "j9hHQcrXqaGT"
      },
      "outputs": [],
      "source": [
        "price_min = df_transac['price'].min()\n",
        "price_med = df_transac['price'].median()\n",
        "price_max = df_transac['price'].max()\n",
        "print('price min: {}, price_med: {}, price max: {}'.format(price_min, price_med, price_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ah851-so5LfS",
      "metadata": {
        "id": "Ah851-so5LfS"
      },
      "outputs": [],
      "source": [
        "\"\"\"histogram of price\n",
        "\n",
        "No display with full dataset...so taking first 10000 rows\"\"\"\n",
        "\n",
        "fig = px.histogram(df_transac[0:100000], x='price')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UIg5nSl4hs8T",
      "metadata": {
        "id": "UIg5nSl4hs8T"
      },
      "outputs": [],
      "source": [
        "\"\"\"data distribution of price\"\"\"\n",
        "\n",
        "fig = px.box(df_transac[0:100000], x=\"price\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tek5eoa_hs2k",
      "metadata": {
        "id": "tek5eoa_hs2k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8hPPYOehsxI",
      "metadata": {
        "id": "M8hPPYOehsxI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o_ReK1-2hssO",
      "metadata": {
        "id": "o_ReK1-2hssO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5yYbxn9hsm-",
      "metadata": {
        "id": "a5yYbxn9hsm-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ridwW4ePhshp",
      "metadata": {
        "id": "ridwW4ePhshp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "64123e7d-74fd-4321-8d21-553579b7d139",
      "metadata": {
        "id": "64123e7d-74fd-4321-8d21-553579b7d139"
      },
      "source": [
        "# Join"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ryqeip0qr_3v",
      "metadata": {
        "id": "ryqeip0qr_3v"
      },
      "source": [
        "- At this point we need to join multiple datasets and get a single one.\n",
        "- This will help to keep consistency along next data processing steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5uUQurwRsoRF",
      "metadata": {
        "id": "5uUQurwRsoRF"
      },
      "source": [
        "- We first join df_transac and df_cust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mkT-Cc027c33",
      "metadata": {
        "id": "mkT-Cc027c33"
      },
      "outputs": [],
      "source": [
        "df_1= pd.merge(df_transac, df_cust, on='customer_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942f82c6-5e2d-4c07-9c5d-413ad6bbd4c6",
      "metadata": {
        "id": "942f82c6-5e2d-4c07-9c5d-413ad6bbd4c6"
      },
      "outputs": [],
      "source": [
        "df_1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nng6WVYst44N",
      "metadata": {
        "id": "nng6WVYst44N"
      },
      "source": [
        "- Then we join df_1 and df_art to gether."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8c963f2-f2ff-4bff-b287-834ddc02eb6f",
      "metadata": {
        "id": "f8c963f2-f2ff-4bff-b287-834ddc02eb6f"
      },
      "outputs": [],
      "source": [
        "df_glob = pd.merge(df_1, df_art, on='article_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i883VcfkuRtK",
      "metadata": {
        "id": "i883VcfkuRtK"
      },
      "outputs": [],
      "source": [
        "df_glob.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccqCDAgSlo7z",
      "metadata": {
        "id": "ccqCDAgSlo7z"
      },
      "outputs": [],
      "source": [
        "df_glob.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gOH8Y80HqzWk",
      "metadata": {
        "id": "gOH8Y80HqzWk"
      },
      "outputs": [],
      "source": [
        "df_glob.isnull().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LlwqwXRqE2un",
      "metadata": {
        "id": "LlwqwXRqE2un"
      },
      "source": [
        "# Clustering with RFM technique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j1C8f58rYkE6",
      "metadata": {
        "id": "j1C8f58rYkE6"
      },
      "source": [
        "- RFM should help in reducing number of samples mainly by focusing on relevant ones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AOkpDgjRE6aA",
      "metadata": {
        "id": "AOkpDgjRE6aA"
      },
      "source": [
        "## Recency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vubYXEJaE91p",
      "metadata": {
        "id": "vubYXEJaE91p"
      },
      "outputs": [],
      "source": [
        "df_glob['t_dat'] = pd.to_datetime(df_glob['t_dat'])\n",
        "most_recent_date = df_glob['t_dat'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m8hr9KtQE9r6",
      "metadata": {
        "id": "m8hr9KtQE9r6"
      },
      "outputs": [],
      "source": [
        "df_glob['recency'] = most_recent_date - df_glob['t_dat']\n",
        "df_glob['recency'] = df_glob['recency'].dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ARdH9w9YGMKs",
      "metadata": {
        "id": "ARdH9w9YGMKs"
      },
      "outputs": [],
      "source": [
        "df_glob['recency'][0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MYk31HGWE-5g",
      "metadata": {
        "id": "MYk31HGWE-5g"
      },
      "source": [
        "## Frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DLwbUvdHFB1q",
      "metadata": {
        "id": "DLwbUvdHFB1q"
      },
      "outputs": [],
      "source": [
        "frequency_data = df_glob.groupby('customer_id')['article_id'].count().reset_index()\n",
        "frequency_data.rename(columns={'article_id': 'frequency'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bRAf_VJaFBuS",
      "metadata": {
        "id": "bRAf_VJaFBuS"
      },
      "outputs": [],
      "source": [
        "df_glob = pd.merge(df_glob, frequency_data, on='customer_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C9CpkPEiFDD8",
      "metadata": {
        "id": "C9CpkPEiFDD8"
      },
      "source": [
        "## Monetory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MiWZHrLUFF02",
      "metadata": {
        "id": "MiWZHrLUFF02"
      },
      "outputs": [],
      "source": [
        "monetary_data = df_glob.groupby('customer_id')['price'].sum().reset_index()\n",
        "monetary_data.rename(columns={'price': 'monetary'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hetBeBs9FFp1",
      "metadata": {
        "id": "hetBeBs9FFp1"
      },
      "outputs": [],
      "source": [
        "df_glob = pd.merge(df_glob, monetary_data, on='customer_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xMLGdKzuHWeO",
      "metadata": {
        "id": "xMLGdKzuHWeO"
      },
      "source": [
        "## RFM Scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BuERInfELWiB",
      "metadata": {
        "id": "BuERInfELWiB"
      },
      "outputs": [],
      "source": [
        "recency_score = pd.qcut(df_glob['recency'], q=5, labels=[5, 4, 3, 2, 1])\n",
        "frequency_score = pd.qcut(df_glob['frequency'], q=5, labels=[1, 2, 3, 4, 5])\n",
        "monetary_score = pd.qcut(df_glob['monetary'], q=5, labels=[1, 2, 3, 4, 5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xj5wONGrKSOk",
      "metadata": {
        "id": "xj5wONGrKSOk"
      },
      "outputs": [],
      "source": [
        "df_glob['recency_score'] = recency_score\n",
        "df_glob['frequency_score'] = frequency_score\n",
        "df_glob['monetary_score'] = monetary_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H25ZwwSzK5lP",
      "metadata": {
        "id": "H25ZwwSzK5lP"
      },
      "outputs": [],
      "source": [
        "df_glob.iloc[0:5, -5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xGo-nNE0Juwd",
      "metadata": {
        "id": "xGo-nNE0Juwd"
      },
      "source": [
        "## Segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GuR4yJAjoxMo",
      "metadata": {
        "id": "GuR4yJAjoxMo"
      },
      "outputs": [],
      "source": [
        "df_glob['rfm_score'] = df_glob['recency_score'].astype(int) + df_glob['frequency_score'].astype(int) + df_glob['monetary_score'].astype(int)\n",
        "cols = ['customer_id', 'recency', 'frequency', 'monetary', 'rfm_score']\n",
        "agg_fn = lambda x: x.sum(axis=0)\n",
        "\n",
        "data_rfm = df_glob.loc[:, cols].groupby(['customer_id']).agg(agg_fn)\n",
        "data_rfm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xr2hX0FkJ4zh",
      "metadata": {
        "id": "Xr2hX0FkJ4zh"
      },
      "outputs": [],
      "source": [
        "segment_labels = ['low_values', 'mid_values', 'high_values']\n",
        "data_rfm['rfm_segment'] = pd.qcut(data_rfm['rfm_score'], q=3, labels=segment_labels)\n",
        "data_rfm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7IpE483wQJhW",
      "metadata": {
        "id": "7IpE483wQJhW"
      },
      "source": [
        "## Display RFM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wG6IeR-45JMm",
      "metadata": {
        "id": "wG6IeR-45JMm"
      },
      "outputs": [],
      "source": [
        "\"\"\"how much of customers per cluster ? \"\"\"\n",
        "s_cust_per_cluster = data_rfm['rfm_segment'].value_counts()\n",
        "s_check = s_cust_per_cluster.sum()\n",
        "\n",
        "print(f'low_values: {s_cust_per_cluster[\"low_values\"]}, percent of total: {s_cust_per_cluster[\"low_values\"]/s_check}')\n",
        "print(f'mid_values: {s_cust_per_cluster[\"mid_values\"]}, percent of total: {s_cust_per_cluster[\"mid_values\"]/s_check}')\n",
        "print(f'high_values: {s_cust_per_cluster[\"high_values\"]}, percent of total: {s_cust_per_cluster[\"high_values\"]/s_check}')\n",
        "print('---')\n",
        "s_check = s_cust_per_cluster.sum()\n",
        "print(f'check: {s_check}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-fjXXET5Iv9",
      "metadata": {
        "id": "u-fjXXET5Iv9"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(s_cust_per_cluster, x=s_cust_per_cluster.index,\n",
        "             y=s_cust_per_cluster.values,\n",
        "             color=s_cust_per_cluster.index,\n",
        "             title='Unique customers per cluster')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJyeYj0K9ME9",
      "metadata": {
        "id": "KJyeYj0K9ME9"
      },
      "source": [
        "- As a conclusion of RFM analysis and as per the objective of taking out of data the ones not relevant enough to the compagny, we could decide to keep mid-values and high-values segments only.\n",
        "- Let's see what would be the results working with k-means methodology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CWUyhKeQ5Hd-",
      "metadata": {
        "id": "CWUyhKeQ5Hd-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "xqreXoiuwrM6",
      "metadata": {
        "id": "xqreXoiuwrM6"
      },
      "source": [
        "# Clustering with K-means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "otsVYcBURi9c",
      "metadata": {
        "id": "otsVYcBURi9c"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZYbhu0NuJ4wW",
      "metadata": {
        "id": "ZYbhu0NuJ4wW"
      },
      "outputs": [],
      "source": [
        "data_rfm_sc = scaler.fit_transform(data_rfm[['recency', 'frequency', 'monetary', 'rfm_score']].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W1N9-VRoJ4lp",
      "metadata": {
        "id": "W1N9-VRoJ4lp"
      },
      "outputs": [],
      "source": [
        "data_rfm_sc[0:5, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U47uyml41iq9",
      "metadata": {
        "id": "U47uyml41iq9"
      },
      "source": [
        "## Importing librairies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vsky-ll01mjl",
      "metadata": {
        "id": "Vsky-ll01mjl"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from yellowbrick.cluster import KElbowVisualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KJQ5WX4UJ4dV",
      "metadata": {
        "id": "KJQ5WX4UJ4dV"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-fdrVLXP1vZi",
      "metadata": {
        "id": "-fdrVLXP1vZi"
      },
      "outputs": [],
      "source": [
        "elbow = KElbowVisualizer(kmeans,k=(2, 20))\n",
        "elbow.fit(data_rfm_sc)\n",
        "elbow.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-8mEwyyw1vNS",
      "metadata": {
        "id": "-8mEwyyw1vNS"
      },
      "outputs": [],
      "source": [
        "n = elbow.elbow_value_\n",
        "kmeans = KMeans(n_clusters=n).fit(data_rfm_sc)\n",
        "centers = kmeans.cluster_centers_\n",
        "clusters = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KrC8-f6x1vIp",
      "metadata": {
        "id": "KrC8-f6x1vIp"
      },
      "outputs": [],
      "source": [
        "data_rfm_sc = np.concatenate([data_rfm_sc, clusters.reshape(-1, 1)], axis=1)\n",
        "print(f'{data_rfm_sc[0:5, :]}')\n",
        "print(f'shape: {data_rfm_sc.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8VX9uVLjv8",
      "metadata": {
        "id": "bb8VX9uVLjv8"
      },
      "outputs": [],
      "source": [
        "data_rfm_sc = np.concatenate([np.asarray(list(data_rfm.index)).reshape(-1, 1), data_rfm_sc], axis=1)\n",
        "print(f'{data_rfm_sc[0:5, :]}')\n",
        "print(f'shape: {data_rfm_sc.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o7zMEB281u2X",
      "metadata": {
        "id": "o7zMEB281u2X"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc = pd.DataFrame(data=data_rfm_sc, columns=['customer_id', 'recency', 'frequency', 'monetary', 'rfm_score', 'clusters'])\n",
        "df_rfm_sc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3gpDSL50Nx2S",
      "metadata": {
        "id": "3gpDSL50Nx2S"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc[['recency', 'frequency', 'monetary', 'rfm_score', 'clusters']] = df_rfm_sc[['recency', 'frequency', 'monetary', 'rfm_score', 'clusters']].astype(float)\n",
        "df_rfm_sc[['clusters']] = df_rfm_sc[['clusters']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rDQ4YhVxP1of",
      "metadata": {
        "id": "rDQ4YhVxP1of"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RtbX6wkYNdqd",
      "metadata": {
        "id": "RtbX6wkYNdqd"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc['clusters'] = df_rfm_sc['clusters'] + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fePkLfkX8rmq",
      "metadata": {
        "id": "fePkLfkX8rmq"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc[df_rfm_sc['clusters'] == 1][0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IAgvQXT187vD",
      "metadata": {
        "id": "IAgvQXT187vD"
      },
      "outputs": [],
      "source": [
        "df_rfm_sc[df_rfm_sc['clusters'] == 6][0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G6AwzTH8-DAl",
      "metadata": {
        "id": "G6AwzTH8-DAl"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data=df_rfm_sc, x='clusters', y='rfm_score', hue='clusters', palette='deep')\n",
        "plt.tight_layout()\n",
        "plt.xlabel('cluster')\n",
        "plt.ylabel('rfm_score')\n",
        "plt.title('RFM score & clusters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7Mr8Zd3qDt6s",
      "metadata": {
        "id": "7Mr8Zd3qDt6s"
      },
      "outputs": [],
      "source": [
        "\"\"\"Counting number of customers per cluster\"\"\"\n",
        "\n",
        "def count_cust_per_cluster(df):\n",
        "  d = {}\n",
        "  for cluster in df['clusters'].unique():\n",
        "    nb_occurencies = len(df[df['clusters'] == cluster])\n",
        "    percent_occurencies = nb_occurencies / len(df)\n",
        "    print(f'--> cluster: {cluster}, nb_occurencies: {nb_occurencies}, percent_occurencies: {percent_occurencies}')\n",
        "    print('---')\n",
        "    d[cluster] = percent_occurencies\n",
        "  print(f'check: {sum(d.values())}')\n",
        "  d = pd.DataFrame(data=d, columns=list(d.keys()), index=range(0,1))\n",
        "  d = d.transpose()\n",
        "  d.rename(columns={0: 'percent_occurencies'}, inplace=True)\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m6g1CcKgINDV",
      "metadata": {
        "id": "m6g1CcKgINDV"
      },
      "outputs": [],
      "source": [
        "df_0 = count_cust_per_cluster(df_rfm_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_Fgbbw0GMfBs",
      "metadata": {
        "id": "_Fgbbw0GMfBs"
      },
      "outputs": [],
      "source": [
        "df_0 = df_0.reset_index(drop=False)\n",
        "df_0.rename(columns={'index': 'cluster'}, inplace=True)\n",
        "df_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jgGIXgaiL4OX",
      "metadata": {
        "id": "jgGIXgaiL4OX"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(df_0, x='cluster', y='percent_occurencies',\n",
        "             color='cluster',\n",
        "             title='Percent of occurencies per cluster',\n",
        "             hover_name='cluster',\n",
        "             hover_data='percent_occurencies')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L-pADK9OPF2q",
      "metadata": {
        "id": "L-pADK9OPF2q"
      },
      "source": [
        "**- We take decision to take cluster#1 out of data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jijTk4ajSrrR",
      "metadata": {
        "id": "jijTk4ajSrrR"
      },
      "outputs": [],
      "source": [
        "\"\"\"merge clusters with df_glob\"\"\"\n",
        "\n",
        "final_rfm_data = df_rfm_sc[['customer_id', 'clusters']]\n",
        "df_glob_clustered = pd.merge(df_glob, final_rfm_data, on='customer_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TRxa3KABSrmF",
      "metadata": {
        "id": "TRxa3KABSrmF"
      },
      "outputs": [],
      "source": [
        "df_glob_clustered.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CdrNhbxtV_Wj",
      "metadata": {
        "id": "CdrNhbxtV_Wj"
      },
      "outputs": [],
      "source": [
        "\"\"\"features to drop\"\"\"\n",
        "print('---')\n",
        "print(f'features before deletion: {len(df_glob_clustered.columns)}')\n",
        "features_to_drop = ['recency', 'frequency', 'monetary']\n",
        "\n",
        "print('---')\n",
        "df_glob_clustered.drop(features_to_drop, axis=1, inplace=True)\n",
        "print(f'features after deletion: {len(df_glob_clustered.columns)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dnZhj1O8den6",
      "metadata": {
        "id": "dnZhj1O8den6"
      },
      "outputs": [],
      "source": [
        "\"\"\"rows to drop:\n",
        "correspond to clusters 1\n",
        "\"\"\"\n",
        "print(f'nb rows before deletion: {len(df_glob_clustered)}')\n",
        "cluster_1 = df_glob_clustered[df_glob_clustered['clusters'] == 1]\n",
        "\n",
        "rows_to_drop = cluster_1.index\n",
        "df_glob_clustered.drop(rows_to_drop, axis=0, inplace=True)\n",
        "print(f'nb rows after deletion: {len(df_glob_clustered)}')\n",
        "print('---')\n",
        "nb_rows_deleted = len(cluster_1)\n",
        "print(f'% rows deleted: {nb_rows_deleted/len(df_glob_clustered)} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v2wWF73ojujd",
      "metadata": {
        "id": "v2wWF73ojujd"
      },
      "outputs": [],
      "source": [
        "\"\"\"reset index\"\"\"\n",
        "df_glob_clustered.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1aYK_KdJIuU",
      "metadata": {
        "id": "h1aYK_KdJIuU"
      },
      "outputs": [],
      "source": [
        "df_glob_clustered.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YFJtoo5uJIaI",
      "metadata": {
        "id": "YFJtoo5uJIaI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6RhWigg7CNkq",
      "metadata": {
        "id": "6RhWigg7CNkq"
      },
      "source": [
        "# Graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wm17Jc_bEC3b",
      "metadata": {
        "id": "Wm17Jc_bEC3b"
      },
      "source": [
        "- Because of computing limitations we cannot grab the whole dataset but just a small part of it.\n",
        "- Unfortunately, we display some months instead of some years."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8MaPviCVsao1",
      "metadata": {
        "id": "8MaPviCVsao1"
      },
      "source": [
        "\n",
        "\n",
        "1.   Number of transactions par day.\n",
        "2.   Number of transactions in function of age.\n",
        "3.   Price of articles per age category.\n",
        "4.   Cumulative sales in volume.\n",
        "5.   Cumulative sales in volume per customer and per age category.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RVIHQSv55PcB",
      "metadata": {
        "id": "RVIHQSv55PcB"
      },
      "outputs": [],
      "source": [
        "\"\"\"are there customers with no purchases ?\"\"\"\n",
        "df_glob_clustered[df_glob_clustered.groupby('customer_id')['price'].transform('count') == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DN4T9VkivaUO",
      "metadata": {
        "id": "DN4T9VkivaUO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "start & ending dates in dataset\n",
        "\"\"\"\n",
        "print(f'start date: {df_glob_clustered[\"t_dat\"].min()}')\n",
        "print(f'end date: {df_glob_clustered[\"t_dat\"].max()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DlpMMwLbzkCg",
      "metadata": {
        "id": "DlpMMwLbzkCg"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "price min & max\n",
        "\"\"\"\n",
        "print(f'price min: {df_glob_clustered[\"price\"].min()}, price max: {df_glob_clustered[\"price\"].max()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ofVZ3IB5CRss",
      "metadata": {
        "id": "ofVZ3IB5CRss"
      },
      "outputs": [],
      "source": [
        "vol = df_glob_clustered.groupby('t_dat')['article_id'].count()\n",
        "fig = go.Figure(data=go.Scatter(x=vol.index, y=vol.values),\n",
        "                layout=go.Layout(title=go.layout.Title(text=\"Number of transactions per day\")))\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHTnIlXbCRZR",
      "metadata": {
        "id": "aHTnIlXbCRZR"
      },
      "outputs": [],
      "source": [
        "vol_age = df_glob_clustered.groupby('age')['article_id'].count()\n",
        "fig = go.Figure(data=go.Scatter(x=vol_age.index, y=vol_age.values),\n",
        "                layout=go.Layout(title=go.layout.Title(text=\"Number of transactions per age\")))\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2JrFRNvyC1tC",
      "metadata": {
        "id": "2JrFRNvyC1tC"
      },
      "outputs": [],
      "source": [
        "\"\"\"build age categories and make scatter of pairs of age category and price\"\"\"\n",
        "df_glob_clustered['age_cat'] = pd.cut(df_glob_clustered['age'], bins=list(np.arange(10, 95, 4)))\n",
        "#scatter_age_cat = df_glob[['age_cat', 'price']]\n",
        "\n",
        "sns.scatterplot(x=df_glob_clustered['age_cat'].astype(str), y=df_glob_clustered['price'], data=df_glob_clustered[['age_cat', 'price']], hue=list(df_glob_clustered['age_cat']))\n",
        "plt.tight_layout()\n",
        "plt.xlabel('age category')\n",
        "plt.ylabel('price')\n",
        "plt.title('Price per age category')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OL2B-5b-zoi_",
      "metadata": {
        "id": "OL2B-5b-zoi_"
      },
      "outputs": [],
      "source": [
        "\"\"\"cumulative sales\"\"\"\n",
        "df_glob_clustered['cum_sales'] = df_glob_clustered['price'].cumsum()\n",
        "fig = sns.lineplot(x='t_dat', y='cum_sales', data=df_glob_clustered)\n",
        "plt.tight_layout()\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('cumulative sales')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ovw_ROS9q8e",
      "metadata": {
        "id": "0ovw_ROS9q8e"
      },
      "outputs": [],
      "source": [
        "df_glob_clustered['sales_by_customer'] = df_glob_clustered.groupby('customer_id')['price'].transform('sum')\n",
        "df_glob_1 = df_glob_clustered.drop_duplicates(subset=['customer_id'])\n",
        "fig = sns.barplot(x='t_dat', y='sales_by_customer', data=df_glob_1)\n",
        "plt.tight_layout()\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('sales by customer')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4f13c9-50a3-46c6-983e-306ed64b5cd2",
      "metadata": {
        "id": "ae4f13c9-50a3-46c6-983e-306ed64b5cd2"
      },
      "source": [
        "# Process missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lYvpXMN3MuhO",
      "metadata": {
        "id": "lYvpXMN3MuhO"
      },
      "source": [
        "## Check missings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jBYfu3GevqOW",
      "metadata": {
        "id": "jBYfu3GevqOW"
      },
      "source": [
        "- We need to focus on features that carry information. Meaning features with too much missing values are not informative enough and have to be taken out."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3803e212-0d88-48c9-8ae0-015545bbf106",
      "metadata": {
        "id": "3803e212-0d88-48c9-8ae0-015545bbf106"
      },
      "source": [
        "If missing rate above 50%, consider to delete features as we would not get data enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d194a1c-f78f-44a5-a3a9-c975b8a480d7",
      "metadata": {
        "id": "8d194a1c-f78f-44a5-a3a9-c975b8a480d7"
      },
      "outputs": [],
      "source": [
        "def miss(df, thres):\n",
        "  l_miss = []\n",
        "\n",
        "  features = list(df.columns)\n",
        "  lengh = len(df)\n",
        "  for feature in features:\n",
        "    missings = df.loc[:,feature].isnull().mean()\n",
        "\n",
        "    if missings > thres:\n",
        "      l_miss.append(feature)\n",
        "  new_df = df.drop(l_miss, axis=1)\n",
        "  print('info--nb cols before: {}, nb cols after: {}'.format(len(df.columns), len(new_df.columns)))\n",
        "  print('suppressed features: {}'.format(l_miss))\n",
        "  return l_miss, new_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62506e57-de08-44fe-89b3-3e55876fa223",
      "metadata": {
        "id": "62506e57-de08-44fe-89b3-3e55876fa223"
      },
      "outputs": [],
      "source": [
        "supp_cols, new_df_glob = miss(df_glob_clustered,thres=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba25769-c187-4665-ab8b-20578c9e9cd9",
      "metadata": {
        "id": "aba25769-c187-4665-ab8b-20578c9e9cd9"
      },
      "source": [
        "## Informative/Non informative features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XqqkfViyynR2",
      "metadata": {
        "id": "XqqkfViyynR2"
      },
      "source": [
        "- We will take out features we estimate not to be informative enough.\n",
        "- Here are full features list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XlLYZT63y5oJ",
      "metadata": {
        "id": "XlLYZT63y5oJ"
      },
      "outputs": [],
      "source": [
        "df_cols = list(new_df_glob.columns)\n",
        "print('features: {}'.format(df_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f0yInJj0PEX",
      "metadata": {
        "id": "3f0yInJj0PEX"
      },
      "source": [
        "- Taken features list we have to check feature category, missing values, informative capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i4GEmiaJ0oIn",
      "metadata": {
        "id": "i4GEmiaJ0oIn"
      },
      "outputs": [],
      "source": [
        "# ==> club_member_status\n",
        "def know_more(feature_text):\n",
        "\n",
        "  return print('dtype: {}, missing: {}, nb of unique: {}, unique: {}'.format(new_df_glob[feature_text].dtype,\n",
        "                                                                    new_df_glob[feature_text].isnull().mean(),\n",
        "                                                                    new_df_glob[feature_text].nunique(),\n",
        "                                                                    new_df_glob[feature_text].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B4GJ5J5M0nwO",
      "metadata": {
        "id": "B4GJ5J5M0nwO"
      },
      "outputs": [],
      "source": [
        "know_more(feature_text='club_member_status')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z0UEnjZcvdx-",
      "metadata": {
        "id": "z0UEnjZcvdx-"
      },
      "source": [
        "- _<font color=\"red\"> --> 'club_member_status' appear as not informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We take out that feature.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p4SA1_9DyhiF",
      "metadata": {
        "id": "p4SA1_9DyhiF"
      },
      "outputs": [],
      "source": [
        "def supp_feature(df, feature):\n",
        "  print('before suppress feature, nb cols: {}'.format(len(list(df.columns))))\n",
        "\n",
        "  df_after = df.drop([feature], axis=1)\n",
        "\n",
        "  print('after suppress feature, nb cols: {}'.format(len(list(df_after.columns))))\n",
        "  return df_after\n",
        "\n",
        "new_df_glob = supp_feature(new_df_glob, 'club_member_status')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gnuZdNkj0nmn",
      "metadata": {
        "id": "gnuZdNkj0nmn"
      },
      "outputs": [],
      "source": [
        "know_more('fashion_news_frequency')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qw5JIoGbwOtI",
      "metadata": {
        "id": "qw5JIoGbwOtI"
      },
      "source": [
        "- _<font color=\"red\"> --> 'fashion_news_frequency' appear as not informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We take out that feature.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2VHWfCXs0mho",
      "metadata": {
        "id": "2VHWfCXs0mho"
      },
      "outputs": [],
      "source": [
        "new_df_glob = supp_feature(new_df_glob, 'fashion_news_frequency')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lqr42oj7tsrh",
      "metadata": {
        "id": "Lqr42oj7tsrh"
      },
      "outputs": [],
      "source": [
        "know_more('prod_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5TeX9Ojlon4N",
      "metadata": {
        "id": "5TeX9Ojlon4N"
      },
      "source": [
        "- _<font color=\"red\"> --> 'prod_name' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ous-W-bt2k5",
      "metadata": {
        "id": "-ous-W-bt2k5"
      },
      "outputs": [],
      "source": [
        "know_more('product_type_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kUkP36Wpo4MC",
      "metadata": {
        "id": "kUkP36Wpo4MC"
      },
      "source": [
        "- _<font color=\"red\"> --> 'product_type_name' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EqcFHUKXtskQ",
      "metadata": {
        "id": "EqcFHUKXtskQ"
      },
      "outputs": [],
      "source": [
        "know_more('product_group_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_fPkdb0yo-vn",
      "metadata": {
        "id": "_fPkdb0yo-vn"
      },
      "source": [
        "- _<font color=\"red\"> --> 'product_group_name' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GaRNM0BMuKaI",
      "metadata": {
        "id": "GaRNM0BMuKaI"
      },
      "outputs": [],
      "source": [
        "know_more('garment_group_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BWp3XqTKpEXa",
      "metadata": {
        "id": "BWp3XqTKpEXa"
      },
      "source": [
        "- _<font color=\"red\"> --> 'garment_group_name' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A8yhiljS2m_E",
      "metadata": {
        "id": "A8yhiljS2m_E"
      },
      "outputs": [],
      "source": [
        "know_more('colour_group_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i6bh93Mf2xH9",
      "metadata": {
        "id": "i6bh93Mf2xH9"
      },
      "source": [
        "- _<font color=\"red\"> --> 'colour_group_name' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GqKKcc1I3VGA",
      "metadata": {
        "id": "GqKKcc1I3VGA"
      },
      "outputs": [],
      "source": [
        "know_more('detail_desc')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rfQtn1rVw7xD",
      "metadata": {
        "id": "rfQtn1rVw7xD"
      },
      "source": [
        "- _<font color=\"red\"> --> 'detail_desc' appear as informative feature.</font>_\n",
        "- _<font color=\"red\"> --> We keep that feature in.</font>_\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "En7dFXhNxcpX",
      "metadata": {
        "id": "En7dFXhNxcpX"
      },
      "source": [
        "- _<font color=\"red\"> --> features with 'code', 'name' (with exceptions) or 'id' are considered as not relevant to characterize products.</font>_\n",
        "- _<font color=\"red\"> --> We take out those features.</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1H9q_Th2i6Tt",
      "metadata": {
        "id": "1H9q_Th2i6Tt"
      },
      "source": [
        "## Deleting features with 'code', or 'name' or 'id'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JXwGMSYEyA2P",
      "metadata": {
        "id": "JXwGMSYEyA2P"
      },
      "outputs": [],
      "source": [
        "#df_art.drop(['product_code'\t,'graphical_appearance_no','product_type_no','colour_group_code','perceived_colour_value_id','perceived_colour_master_id','department_no','index_code','index_group_no','section_no','garment_group_no' ], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de2e85e-f9f2-4649-ab5e-6979700813f0",
      "metadata": {
        "id": "9de2e85e-f9f2-4649-ab5e-6979700813f0"
      },
      "outputs": [],
      "source": [
        "def supp_non_inf(df):\n",
        "  s_1 = '_no'\n",
        "  s_2 = '_code'\n",
        "\n",
        "  cols_tobe_deleted = [element for element in list(new_df_glob.columns) if (s_1 in element) or (s_2 in element)]\n",
        "  df_after = df.drop(cols_tobe_deleted, axis=1)\n",
        "  print('before supp: {}, after supp: {}'.format(len(df.columns), len(df_after.columns)))\n",
        "  print('remaining features: {}'.format(list(df_after.columns)))\n",
        "  return df_after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EsbCVkwKPVW8",
      "metadata": {
        "id": "EsbCVkwKPVW8"
      },
      "outputs": [],
      "source": [
        "df_glob_after = supp_non_inf(new_df_glob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aCb1PC9x4jcb",
      "metadata": {
        "id": "aCb1PC9x4jcb"
      },
      "outputs": [],
      "source": [
        "def supp_other_non_inf(df):\n",
        "  cols = list(df.columns)\n",
        "  print('nb cols before: {}'.format(len(cols)))\n",
        "  # elements with 'name' in it we have to keep\n",
        "  s_01 = 'prod_name'\n",
        "  s_02 = 'product_type_name'\n",
        "  s_03 = 'product_group_name'\n",
        "  s_04 = 'garment_group_name'\n",
        "\n",
        "  s_1 = 'colour' # keep element if colour is in\n",
        "  s_2 = 'name' # not to keep element if name is in AND colour not in\n",
        "\n",
        "\n",
        "  # delete columns with 'name' in it, except if 'colour' is in it\n",
        "  rem_cols_1 = [element for element in cols if\n",
        "   (s_2 not in element) or\n",
        "    (s_2 and s_1 in element) or\n",
        "     (s_01 in element) or\n",
        "      (s_02 in element) or\n",
        "       (s_03 in element) or\n",
        "        (s_04 in element)]\n",
        "\n",
        "  # delete columns with 'id' in it except if 'id' is associated with 'customer' or 'article'\n",
        "  s_3 = 'id'\n",
        "  s_4 = 'customer'\n",
        "  s_5 = 'article'\n",
        "  rem_cols_2 = [element for element in rem_cols_1 if (s_3 not in element) or (s_3 and s_4 in element) or (s_3 and s_5 in element)]\n",
        "\n",
        "  print('nb cols after: {}'.format(len(rem_cols_2)))\n",
        "  print('cols after: {}'.format(rem_cols_2))\n",
        "\n",
        "  df_cleaned = df.loc[:,rem_cols_2]\n",
        "\n",
        "  return df_cleaned\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wj1qLDfc4jMo",
      "metadata": {
        "id": "Wj1qLDfc4jMo"
      },
      "outputs": [],
      "source": [
        "df_cleaned = supp_other_non_inf(df_glob_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3J-F9vA_iddJ",
      "metadata": {
        "id": "3J-F9vA_iddJ"
      },
      "source": [
        "### df_cleaned info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xsq9mApqEPXO",
      "metadata": {
        "id": "Xsq9mApqEPXO"
      },
      "outputs": [],
      "source": [
        "df_cleaned.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XDpnOtj2E0_g",
      "metadata": {
        "id": "XDpnOtj2E0_g"
      },
      "source": [
        "- _<font color=\"red\"> --> We see \"age\" feature has missing quite a lot of missings.</font>_\n",
        "- _<font color=\"red\"> --> We have to find a way to predict missings.</font>_\n",
        "- _<font color=\"red\"> --> This is the next step.</font>_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddQxJ3W7zUPY",
      "metadata": {
        "id": "ddQxJ3W7zUPY"
      },
      "source": [
        "## Question of encoding categorical features; Checking number of unique values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vejIHZVt9gH9",
      "metadata": {
        "id": "vejIHZVt9gH9"
      },
      "source": [
        "- This section provide us with information on how to encode cataegorical features.\n",
        "- If unique values for each feature is about of some elements (not thousands !), then we could go with OneHotEncoder() methodology.\n",
        "- If not, we will go with text encoding (NLP) methodology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "np4PUGGx2kFb",
      "metadata": {
        "id": "np4PUGGx2kFb"
      },
      "outputs": [],
      "source": [
        "def check_unique_val(df, feature):\n",
        "  return print(f'number of unique values: {df[feature].nunique()}, unique values: {df[feature].unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zlMXhFlhtRYZ",
      "metadata": {
        "id": "zlMXhFlhtRYZ"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'prod_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mwl6OAC2tQPY",
      "metadata": {
        "id": "mwl6OAC2tQPY"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'product_type_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oD_zsiwmtQG3",
      "metadata": {
        "id": "oD_zsiwmtQG3"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'product_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Usc_8LoG2j1-",
      "metadata": {
        "id": "Usc_8LoG2j1-"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'colour_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bezZ-8xj2jpd",
      "metadata": {
        "id": "bezZ-8xj2jpd"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'perceived_colour_value_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-lyJGnFHEyqg",
      "metadata": {
        "id": "-lyJGnFHEyqg"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned, 'perceived_colour_master_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "btHJQdG2tzSM",
      "metadata": {
        "id": "btHJQdG2tzSM"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned,'garment_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IhdQS7IO-R-d",
      "metadata": {
        "id": "IhdQS7IO-R-d"
      },
      "outputs": [],
      "source": [
        "check_unique_val(df_cleaned,'detail_desc')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HkPi0lWTwrCj",
      "metadata": {
        "id": "HkPi0lWTwrCj"
      },
      "source": [
        "- _<font color=\"red\"> --> We have height categorical features.</font>_\n",
        "- _<font color=\"red\"> --> In order to be consistent in next steps we have to encode these features in order to convert categorical features into numeric ones.</font>_\n",
        "- _<font color=\"red\"> --> We have to use same methodology for encoding.</font>_\n",
        "- _<font color=\"red\"> --> We will use embedding methodology using model from Huggingface.</font>_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pzPdHeDwTdVZ",
      "metadata": {
        "id": "pzPdHeDwTdVZ"
      },
      "source": [
        "## **Missings in \"age\" feature. --> # First try**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F1LuipZOp_-l",
      "metadata": {
        "id": "F1LuipZOp_-l"
      },
      "source": [
        "- We try a simple impting method using SimpleImputer from sklearn.\n",
        "- Have to import corresponding modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bsnUoj0rp9UG",
      "metadata": {
        "id": "bsnUoj0rp9UG"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BwvAR_xKp9Mj",
      "metadata": {
        "id": "BwvAR_xKp9Mj"
      },
      "outputs": [],
      "source": [
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wpNIiO7vp9EZ",
      "metadata": {
        "id": "wpNIiO7vp9EZ"
      },
      "outputs": [],
      "source": [
        "feature_age = df_cleaned[['age']]\n",
        "print(f'feature_age.shape: {feature_age.shape}')\n",
        "\n",
        "X = imp.fit_transform(feature_age)\n",
        "print(f'X.shape: {X.shape}')\n",
        "print(f'X null values: {np.isnan(X).sum()}')\n",
        "\n",
        "df_cleaned['age_imputed'] = X\n",
        "df_cleaned['age_imputed'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D_o9DL54p87e",
      "metadata": {
        "id": "D_o9DL54p87e"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df_cleaned['age_imputed'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PupnBESHvsJd",
      "metadata": {
        "id": "PupnBESHvsJd"
      },
      "source": [
        "- <font color='red'> Conclusion: model not capable to output proper predictions.</font>\n",
        "- <font color='red'> We see data is not enough distributed after imputation, whatever we use MEAN or MEDIAN</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtiO9rXPvmhd",
      "metadata": {
        "id": "vtiO9rXPvmhd"
      },
      "source": [
        "## **Missings in \"age\" feature. --> # Second try**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86KUEOHsw62w",
      "metadata": {
        "id": "86KUEOHsw62w"
      },
      "source": [
        "- we will try KNN imputer from sklearn.\n",
        "- Have to import related modules.\n",
        "- Have to scale features 'age' and 'price'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JKH0azHLqjvz",
      "metadata": {
        "id": "JKH0azHLqjvz"
      },
      "outputs": [],
      "source": [
        "df_cleaned.iloc[0:2, -6:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cv2GqzO5p8Z3",
      "metadata": {
        "id": "cv2GqzO5p8Z3"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tpkj3GaWxRdh",
      "metadata": {
        "id": "Tpkj3GaWxRdh"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5TSc-9acxROy",
      "metadata": {
        "id": "5TSc-9acxROy"
      },
      "outputs": [],
      "source": [
        "X_1 = df_cleaned[['age', 'rfm_score']]\n",
        "X_1_sc = scaler.fit_transform(X_1)\n",
        "print(f'X_1_sc.shape: {X_1_sc.shape}')\n",
        "X_1_sc[0:5, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hR7bigFU5hQJ",
      "metadata": {
        "id": "hR7bigFU5hQJ"
      },
      "outputs": [],
      "source": [
        "X_price_sc = df_cleaned[['price']].values\n",
        "\n",
        "X_sc = np.concatenate([X_1_sc, X_price_sc], axis=1)\n",
        "X_sc[0:5, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82CIZTFxRAi",
      "metadata": {
        "id": "d82CIZTFxRAi"
      },
      "outputs": [],
      "source": [
        "imputer = KNNImputer(n_neighbors=5, weights='uniform')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6jrKB8Z_xQ80",
      "metadata": {
        "id": "6jrKB8Z_xQ80"
      },
      "outputs": [],
      "source": [
        "imputed = imputer.fit_transform(X_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GPgQ2aETxQ3b",
      "metadata": {
        "id": "GPgQ2aETxQ3b"
      },
      "outputs": [],
      "source": [
        "imputed_inverse = scaler.inverse_transform(imputed[:, 0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DTUTthxsxQor",
      "metadata": {
        "id": "DTUTthxsxQor"
      },
      "outputs": [],
      "source": [
        "imputed_inverse[0:5, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CZj8jI4F0YUJ",
      "metadata": {
        "id": "CZj8jI4F0YUJ"
      },
      "outputs": [],
      "source": [
        "df_cleaned['age_imputed'] = imputed_inverse[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vz6JCU6W0YQA",
      "metadata": {
        "id": "vz6JCU6W0YQA"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df_cleaned['age_imputed'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jdryfSi90YLB",
      "metadata": {
        "id": "jdryfSi90YLB"
      },
      "outputs": [],
      "source": [
        "df_cleaned['age_imputed'].isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4NSSnn-G0Xyx",
      "metadata": {
        "id": "4NSSnn-G0Xyx"
      },
      "outputs": [],
      "source": [
        "df_cleaned_1 = df_cleaned.drop(['age'], axis=1)\n",
        "df_cleaned_1.rename(columns={'age_imputed': 'age'}, inplace=True)\n",
        "df_cleaned_1.isnull().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "paNghaWrKUXq",
      "metadata": {
        "id": "paNghaWrKUXq"
      },
      "source": [
        "- <font color='red'> Conclusion: we keep that methodology for age feature prediction as data distribution is more in line with expectations.</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dgte6M5xK2-h",
      "metadata": {
        "id": "dgte6M5xK2-h"
      },
      "source": [
        "## **Missings in \"detail_desc\" feature.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T0N643xWjKMb",
      "metadata": {
        "id": "T0N643xWjKMb"
      },
      "source": [
        "- We know there are missing values in \"detail_desc\".\n",
        "- These missing values â€‹â€‹correspond to a value of the article_id value and are intended to give a qualitative description of the article.\n",
        "- If we can find that same article_id somewhere in the dataset, then we can get the missing article_id.\n",
        "- In the other way, if we cannot find that \"article_id\" elsewhere in the dataset, then it is impossible to deduct \"detail_desc\" value from other data in the dataset.\n",
        "- In that case we will delete related rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zEbwO7e4GTvz",
      "metadata": {
        "id": "zEbwO7e4GTvz"
      },
      "source": [
        "### Divide data set into 'with null values' and 'not null values'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "itl4QoSoJJQu",
      "metadata": {
        "id": "itl4QoSoJJQu"
      },
      "outputs": [],
      "source": [
        "df_cleaned_2 = df_cleaned_1[df_cleaned_1['detail_desc'].notna()]\n",
        "df_cleaned_2.info()\n",
        "print()\n",
        "\"\"\"\n",
        "Once embedding process is done, we will need to gather\n",
        "df_cleaned_2 which is not null, with the rest of the data.\n",
        "\"\"\"\n",
        "df_cleaned_2_withna = df_cleaned_1[df_cleaned_1['detail_desc'].isna()]\n",
        "df_cleaned_2_withna.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIvYNy7Wj8gw",
      "metadata": {
        "id": "vIvYNy7Wj8gw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "build list of article_id with missing values.\n",
        "then see if there are any article_id in df_cleaned_2\n",
        "\"\"\"\n",
        "print('---------')\n",
        "list_article_id_withna = list(df_cleaned_2_withna['article_id'])\n",
        "df_try = df_cleaned_2['article_id'].isin(list_article_id_withna)\n",
        "print(f'check if we can find \"detail_desc\" missing values somewhere in dataset: {df_try.isnull().sum()}')\n",
        "print()\n",
        "if df_try.isnull().sum() == 0:\n",
        "  print(f'we cannot find \"detail_desc\" missing values somewhere in dataset,\\n we have to delete rows with missing values.\\n we are left with df_cleaned_2 only')\n",
        "print('---------')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGsyX6DJDg2P",
      "metadata": {
        "id": "qGsyX6DJDg2P"
      },
      "source": [
        "### df_cleaned_2.info()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sWRhmzREmsGB",
      "metadata": {
        "id": "sWRhmzREmsGB"
      },
      "outputs": [],
      "source": [
        "\"\"\"Therefore, after deletion we are left with \"df_cleaned_2\"\"\"\n",
        "df_cleaned_2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C7OPHiaXoXfw",
      "metadata": {
        "id": "C7OPHiaXoXfw"
      },
      "outputs": [],
      "source": [
        "cleaned_cols = list(df_cleaned_2.columns)\n",
        "print(f'cleaned_cols -- names: {cleaned_cols}, \\n number -- {len(cleaned_cols)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mfA4-w1kKv0-",
      "metadata": {
        "id": "mfA4-w1kKv0-"
      },
      "source": [
        "# **Embeddings.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MVzbAFmlv_pZ",
      "metadata": {
        "id": "MVzbAFmlv_pZ"
      },
      "source": [
        "## Importing modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6961ee0-09fc-4b4a-a741-db4894a0de5a",
      "metadata": {
        "id": "c6961ee0-09fc-4b4a-a741-db4894a0de5a"
      },
      "outputs": [],
      "source": [
        "#!pip install sentence_transformers\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5U0bUj3zwOJ0",
      "metadata": {
        "id": "5U0bUj3zwOJ0"
      },
      "source": [
        "## Model for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4yvuMkFMlw0a",
      "metadata": {
        "id": "4yvuMkFMlw0a"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"\n",
        "#model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YHCVsY7c_CjG",
      "metadata": {
        "id": "YHCVsY7c_CjG"
      },
      "source": [
        "## Select categorical features & non categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s45IBET6_x3L",
      "metadata": {
        "id": "s45IBET6_x3L"
      },
      "outputs": [],
      "source": [
        "cat_cols = list(df_cleaned_2.select_dtypes(include=['object']))\n",
        "print(f'cat_cols: {cat_cols}, \\n nb: {len(cat_cols)}')\n",
        "\n",
        "non_cat_cols = list(df_cleaned_2.select_dtypes(exclude=['object']))\n",
        "print(f'non_cat_cols: {non_cat_cols}, \\n nb: {len(non_cat_cols)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd3ZdkiCgHm5",
      "metadata": {
        "id": "dd3ZdkiCgHm5"
      },
      "source": [
        "## Down sampling for memory limitation constraint."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-5IJTiH2gRsf",
      "metadata": {
        "id": "-5IJTiH2gRsf"
      },
      "source": [
        "- We will only consider customer who are active.\n",
        "- Active means: at least one purchase per month.\n",
        "- If non purchase during the month, customer will be taken out of dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cuLbVcSN7MQP",
      "metadata": {
        "id": "cuLbVcSN7MQP"
      },
      "outputs": [],
      "source": [
        "\"\"\"Filter on rows for which customer's purchases are less than 10 ITEMS PER MONTH\"\"\"\n",
        "\n",
        "def filter_on_purchase(df):\n",
        "  print(f'nb of rows before deletion: {len(df)}')\n",
        "\n",
        "  df_final = pd.DataFrame()\n",
        "  d = {}\n",
        "\n",
        "  \"\"\"build monthly periods\"\"\"\n",
        "  start_date = df['t_dat'].min()\n",
        "  end_date = df['t_dat'].max()\n",
        "  nb_of_months = (end_date - start_date).days//30\n",
        "  print(f'nb_of_months: {nb_of_months}')\n",
        "\n",
        "  for month in range(nb_of_months):\n",
        "    print(f'{month}')\n",
        "    if start_date + pd.Timedelta(days=30 * month) <= df['t_dat'].max():\n",
        "\n",
        "      end_date = start_date + pd.Timedelta(days=30 * month) + pd.Timedelta(days=30)\n",
        "      #print(f'start_date: {start_date + pd.Timedelta(days=30 * month)}')\n",
        "      #print(f'end_date: {end_date}')\n",
        "\n",
        "      df_temp_1 = df[(df['t_dat'] >= start_date + pd.Timedelta(days=30 * month)) & (df['t_dat'] < end_date)]\n",
        "      print(f'df_temp_1.shape: {df_temp_1.shape}')\n",
        "\n",
        "      \"\"\"list of indexes for which customer's purchases are less than 10 per month\"\"\"\n",
        "      list_of_indexes = list(df_temp_1.groupby(['customer_id'])['article_id'].filter(lambda x: x.count() <= 10).index)\n",
        "      print(f'list_of_indexes: {len(list_of_indexes)}')\n",
        "\n",
        "\n",
        "      \"\"\"delete rows\"\"\"\n",
        "      df_filtered = df_temp_1.drop(list_of_indexes)\n",
        "      print(f'df_filtered.shape: {df_filtered.shape}')\n",
        "\n",
        "\n",
        "      \"\"\"append df_filtered to df_final\"\"\"\n",
        "      df_final = pd.concat([df_final, df_filtered])\n",
        "      print(f'df_final.shape: {df_final.shape}')\n",
        "      df_final = df_final.reset_index(drop=True)\n",
        "\n",
        "      \"\"\"fill d\"\"\"\n",
        "      d[month] = len(list_of_indexes)\n",
        "\n",
        "  df_del_rows = pd.DataFrame.from_dict(d, orient='index')\n",
        "  df_del_rows.rename(columns={0: 'deleted_rows_per_month'}, inplace=True)\n",
        "  df_del_rows.index.name = 'month'\n",
        "\n",
        "\n",
        "\n",
        "  return df_del_rows, df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YYxp7Ibw7MI1",
      "metadata": {
        "id": "YYxp7Ibw7MI1"
      },
      "outputs": [],
      "source": [
        "df_del_rows, df_cleaned_2_masked = filter_on_purchase(df_cleaned_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=df_del_rows, x=df_del_rows.index, y='deleted_rows_per_month')\n",
        "plt.title('nb of deleted rows per Month')\n",
        "plt.xlabel('period')\n",
        "plt.ylabel('nb of deleted rows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oSvaJQBmUd4h"
      },
      "id": "oSvaJQBmUd4h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1EbRgTCcLByP",
      "metadata": {
        "id": "1EbRgTCcLByP"
      },
      "source": [
        "## df_cleaned_2masked info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2E5f9kPbixXA",
      "metadata": {
        "id": "2E5f9kPbixXA"
      },
      "outputs": [],
      "source": [
        "df_cleaned_2_masked.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hHmaigGBixDs",
      "metadata": {
        "id": "hHmaigGBixDs"
      },
      "outputs": [],
      "source": [
        "def check_buyings(df):\n",
        "  \"\"\"this function is used to take customers out of the dataset if they do not\n",
        "  purchase at least 10 ITEMS PER WEEK.\n",
        "  \"\"\"\n",
        "\n",
        "  print(f'nb rows before deletion: {len(df)}')\n",
        "  len_rows_to_be_deleted = 0\n",
        "  days_increment= 7\n",
        "  df_final = pd.DataFrame()\n",
        "  d = {}\n",
        "\n",
        "  start_date = df['t_dat'].min()\n",
        "  max_date = df['t_dat'].max()\n",
        "  nb_of_days = (max_date - start_date).days\n",
        "  nb_of_periods_of_7_days = nb_of_days//days_increment\n",
        "\n",
        "  \"\"\"prints\"\"\"\n",
        "  print(f'nb_of_days: {nb_of_days}')\n",
        "  print(f'nb_of_periods_of_7_days: {nb_of_periods_of_7_days}')\n",
        "\n",
        "\n",
        "  for period in range(0, nb_of_periods_of_7_days):\n",
        "\n",
        "    start_date_period = start_date\n",
        "    end_date = start_date_period + pd.Timedelta(days=days_increment)\n",
        "    df_temp_1 = df[(df['t_dat'] >= start_date_period) & (df['t_dat'] < end_date)]\n",
        "\n",
        "    \"\"\"prints\"\"\"\n",
        "    print('---')\n",
        "    print(f'start_date_period: {start_date_period}')\n",
        "    print(f'period: {period}, nb days -- {pd.Timedelta(days=days_increment * period)}')\n",
        "    print(f'end_date: {end_date}')\n",
        "    print()\n",
        "    print(f'{df_temp_1[\"t_dat\"].min()}')\n",
        "    print(f'{df_temp_1[\"t_dat\"].max()}')\n",
        "    #print((f'df_temp_1: {df_temp_1[0:4]}'))\n",
        "\n",
        "    \"\"\"list of indexes for which customer's purchases are less than 1 per month\"\"\"\n",
        "    list_of_indexes = list(df_temp_1.groupby(['customer_id'])['article_id'].filter(lambda x: x.count() <= 10).index)\n",
        "    print(f'list_of_indexes: {len(list_of_indexes)}')\n",
        "\n",
        "    \"\"\"append nb of deleted rows to d\n",
        "    \"\"\"\n",
        "    d[period] = len(list_of_indexes)\n",
        "\n",
        "\n",
        "    \"\"\"delete rows\"\"\"\n",
        "    df_filtered = df_temp_1.drop(list_of_indexes)\n",
        "    print(f'df_filtered.shape: {df_filtered.shape}')\n",
        "\n",
        "\n",
        "    \"\"\"append df_filtered to df_final\"\"\"\n",
        "    df_final = pd.concat([df_final, df_filtered])\n",
        "    print(f'df_final.shape: {df_final.shape}')\n",
        "    df_final = df_final.reset_index(drop=True)\n",
        "\n",
        "    start_date = end_date\n",
        "\n",
        "  \"\"\"put d into df\"\"\"\n",
        "  print(f'd: {d}')\n",
        "  df_del_rows = pd.DataFrame.from_dict(d, orient='index')\n",
        "  df_del_rows.rename(columns={0: 'deleted_rows_per_period'}, inplace=True)\n",
        "  df_del_rows.index.name = 'period'\n",
        "  print(f'df_del_rows[0:5]: {df_del_rows[0:5]}')\n",
        "  #print(f'df_del_rows.shape: {df_del_rows.shape}')\n",
        "\n",
        "  print(f'nb rows after deletion: {len(df_final)}')\n",
        "\n",
        "  return df_del_rows, df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yMsUmnyBiw6Q",
      "metadata": {
        "id": "yMsUmnyBiw6Q"
      },
      "outputs": [],
      "source": [
        "df_del_rows, df_cleaned_2_reduced = check_buyings(df_cleaned_2_masked)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=df_del_rows, x=df_del_rows.index, y='deleted_rows_per_period')\n",
        "plt.title('nb of deleted rows per period of seven days')\n",
        "plt.xlabel('period')\n",
        "plt.ylabel('nb of deleted rows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mz3upk7MPjR7"
      },
      "id": "Mz3upk7MPjR7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V8HXKPdL-Ff5",
      "metadata": {
        "id": "V8HXKPdL-Ff5"
      },
      "outputs": [],
      "source": [
        "df_cleaned_2_reduced.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U4WH-2AdRwqg",
      "metadata": {
        "id": "U4WH-2AdRwqg"
      },
      "source": [
        "## Drop some features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3MkQ0mqTR9c",
      "metadata": {
        "id": "a3MkQ0mqTR9c"
      },
      "source": [
        "- Features not to be used in next setps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yeo5Pjl7RxdX",
      "metadata": {
        "id": "yeo5Pjl7RxdX"
      },
      "outputs": [],
      "source": [
        "\"\"\"drop some features we do not need\"\"\"\n",
        "features_to_be_dropped = ['perceived_colour_value_name','perceived_colour_master_name',\n",
        "                          'recency_score', 'frequency_score','monetary_score',\n",
        "                         'rfm_score', 'clusters', 'age_cat', 'cum_sales',\n",
        "                         'sales_by_customer']\n",
        "df_cleaned_2_reduced = df_cleaned_2_reduced.drop(features_to_be_dropped, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## df_cleaned_2_reduced.info()"
      ],
      "metadata": {
        "id": "bnM7GVSrQGD5"
      },
      "id": "bnM7GVSrQGD5"
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_2_reduced.info()"
      ],
      "metadata": {
        "id": "l1_oWK_pQMaC"
      },
      "id": "l1_oWK_pQMaC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ZoSzC_YyiPOZ",
      "metadata": {
        "id": "ZoSzC_YyiPOZ"
      },
      "source": [
        "## Graphs: Best customer behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XoKlecF_inKS",
      "metadata": {
        "id": "XoKlecF_inKS"
      },
      "source": [
        "Best customers analysis:\n",
        "- how many customers ?\n",
        "- In average, customer spending ?\n",
        "- In average, number of articles purchased per week per customer ?\n",
        "- Which \"product_type_name\" is purchased most ?\n",
        "- Which \"product_group_name\" is purchased most ?   \n",
        "- Wich \"colour_group_name\" is purchased most ?\n",
        "- Wich \"garment_group_name\" is purchased most ?\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u30pOtf1iwyY",
      "metadata": {
        "id": "u30pOtf1iwyY"
      },
      "outputs": [],
      "source": [
        "nb_customers = df_cleaned_2_reduced['customer_id'].nunique()\n",
        "print(f'nb_customers: {nb_customers}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DBrWP7Z2hbCw",
      "metadata": {
        "id": "DBrWP7Z2hbCw"
      },
      "outputs": [],
      "source": [
        "spendings = df_cleaned_2_reduced.groupby('customer_id')['price'].sum()\n",
        "print(f'spendings.shape: {spendings.shape}')\n",
        "fig = px.histogram(spendings, title='spending by customer')\n",
        "fig.show()\n",
        "\n",
        "top_100_spendings = spendings.sort_values(ascending=False)[0:100]\n",
        "print(f'top_100_spendings.shape: {top_100_spendings.shape}')\n",
        "fig = px.histogram(top_100_spendings, title='spending for top 100 customers')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nLptaikBlvyv",
      "metadata": {
        "id": "nLptaikBlvyv"
      },
      "outputs": [],
      "source": [
        "purchasings = df_cleaned_2_reduced.groupby('customer_id')['article_id'].count()\n",
        "print(f'purchasings.shape: {purchasings.shape}')\n",
        "fig = px.histogram(purchasings, title='nb of articles purchased by customer')\n",
        "fig.show()\n",
        "\n",
        "top_100_purchasings = purchasings.sort_values(ascending=False)[0:100]\n",
        "print(f'top_100_purchasings.shape: {top_100_purchasings.shape}')\n",
        "fig = px.histogram(top_100_purchasings, title='nb of articles purchased by top 100 customers')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UCr77HOtsD_W",
      "metadata": {
        "id": "UCr77HOtsD_W"
      },
      "outputs": [],
      "source": [
        "def display_prod_types(feature):\n",
        "  prod_type_name = df_cleaned_2_reduced[feature]\n",
        "  fig = px.histogram(prod_type_name, title=feature)\n",
        "  fig.show()\n",
        "\n",
        "  most_purchased_prod_type = prod_type_name.value_counts().index[0:50]\n",
        "  #print(f'most_purchased_prod_type: {most_purchased_prod_type}')\n",
        "  fig = px.bar(prod_type_name.value_counts(), title='most purchased' + ' ' + feature)\n",
        "  fig.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "urnCq_lIsD3o",
      "metadata": {
        "id": "urnCq_lIsD3o"
      },
      "outputs": [],
      "source": [
        "display_prod_types('product_type_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DyHy7RONsDu-",
      "metadata": {
        "id": "DyHy7RONsDu-"
      },
      "outputs": [],
      "source": [
        "display_prod_types('product_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5doKArtqAfg",
      "metadata": {
        "id": "Y5doKArtqAfg"
      },
      "outputs": [],
      "source": [
        "display_prod_types('colour_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PgaApEOzqAak",
      "metadata": {
        "id": "PgaApEOzqAak"
      },
      "outputs": [],
      "source": [
        "display_prod_types('garment_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(df_glob['index_name'].value_counts(), title='nb purchases by index name', color=df_glob['index_name'].unique())\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "alWqZO9vUFUA"
      },
      "id": "alWqZO9vUFUA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(df_glob['department_name'].value_counts(), title='nb purchases by dpt. name')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yssRFhIfSkG9"
      },
      "id": "yssRFhIfSkG9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GG2GIHx_JoSM",
      "metadata": {
        "id": "GG2GIHx_JoSM"
      },
      "outputs": [],
      "source": [
        "counts_per_customer = df_cleaned_2_reduced.groupby(['customer_id'],\n",
        "                                                   as_index=False)['article_id'].count().sort_values(by=['article_id'], ascending=False)[0:100]\n",
        "\n",
        "counts_per_customer.rename(columns={'article_id': 'nb of articles'}, inplace=True)\n",
        "counts_per_customer.set_index('customer_id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3REI4SJoBm",
      "metadata": {
        "id": "dd3REI4SJoBm"
      },
      "outputs": [],
      "source": [
        "mean_counts_per_cust = counts_per_customer.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blyz-CM-Jnzi",
      "metadata": {
        "id": "blyz-CM-Jnzi"
      },
      "outputs": [],
      "source": [
        "ax = sns.barplot(x=counts_per_customer.index,\n",
        "            y=counts_per_customer['nb of articles'],\n",
        "                 color='green')\n",
        "ax.set(xlabel='customer_id', ylabel='nb of articles')\n",
        "ax.set_title('nb of articles purchased by top 100 customers')\n",
        "#ax.tick_params(labelrotation=45)\n",
        "ax.axhline(y = mean_counts_per_cust[0],\n",
        "           color = 'r',\n",
        "           linestyle = 'dashed',\n",
        "           xmin = 0.1,\n",
        "           xmax = 0.9)\n",
        "plt.title('nb of articles purchased by top 100 customers vs mean')\n",
        "plt.xlabel('customer_id')\n",
        "plt.ylabel('nb of articles')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9kCzPQUAY7r",
      "metadata": {
        "id": "d9kCzPQUAY7r"
      },
      "source": [
        "## Get embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zD6JVpzcwwo8",
      "metadata": {
        "id": "zD6JVpzcwwo8"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Z25czQXOA--",
      "metadata": {
        "id": "1Z25czQXOA--"
      },
      "outputs": [],
      "source": [
        "def tolist_fn(df, feature):\n",
        "  \"\"\"get unique values of a feature\"\"\"\n",
        "  unique_val = df[feature].unique()\n",
        "  print(f'unique_val.shape: {len(unique_val)}')\n",
        "  feature_as_list = unique_val.tolist()\n",
        "  print(f'feature_as_list.shape: {len(feature_as_list)}')\n",
        "  return feature_as_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "euPPm3xrR_89",
      "metadata": {
        "id": "euPPm3xrR_89"
      },
      "outputs": [],
      "source": [
        "detail_desc_tolist = tolist_fn(df_cleaned_2_reduced, 'detail_desc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2MVhIfLYSWPx",
      "metadata": {
        "id": "2MVhIfLYSWPx"
      },
      "outputs": [],
      "source": [
        "garment_type_tolist = tolist_fn(df_cleaned_2_reduced, 'garment_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3BCLsB81SrBN",
      "metadata": {
        "id": "3BCLsB81SrBN"
      },
      "outputs": [],
      "source": [
        "color_group_name_tolist = tolist_fn(df_cleaned_2_reduced, 'colour_group_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_wA-CfPuoe9D",
      "metadata": {
        "id": "_wA-CfPuoe9D"
      },
      "outputs": [],
      "source": [
        "detail_desc_vect = model.encode(detail_desc_tolist)\n",
        "print(f'detail_desc_vect.shape: {detail_desc_vect.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FsPEgTnfuVE7",
      "metadata": {
        "id": "FsPEgTnfuVE7"
      },
      "outputs": [],
      "source": [
        "garment_vect = model.encode(garment_type_tolist)\n",
        "print(f'garment_vect.shape: {garment_vect.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ctjgt4olulG9",
      "metadata": {
        "id": "Ctjgt4olulG9"
      },
      "outputs": [],
      "source": [
        "color_vect = model.encode(color_group_name_tolist)\n",
        "print(f'color_vect.shape: {color_vect.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WsrxYo8nTI4H",
      "metadata": {
        "id": "WsrxYo8nTI4H"
      },
      "source": [
        "## Dimension reduction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tRJcSk7dA55F",
      "metadata": {
        "id": "tRJcSk7dA55F"
      },
      "outputs": [],
      "source": [
        "def dim_red(vect):\n",
        "  n_components = vect.shape[1]//32\n",
        "  pca = PCA(n_components=n_components)\n",
        "  vect_pca = pca.fit_transform(vect)\n",
        "  print(f'vect_pca.shape: {vect_pca.shape}')\n",
        "\n",
        "  return n_components,vect_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "niwmy4ODTTtj",
      "metadata": {
        "id": "niwmy4ODTTtj"
      },
      "outputs": [],
      "source": [
        "n_components, pca_detail_desc = dim_red(detail_desc_vect)\n",
        "print(f'pca_detail_desc.shape: {pca_detail_desc.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VOZsIJ_TT4rb",
      "metadata": {
        "id": "VOZsIJ_TT4rb"
      },
      "outputs": [],
      "source": [
        "n_components, pca_garment = dim_red(garment_vect)\n",
        "print(f'pca_garment.shape: {pca_garment.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rDvHoVGkT4gg",
      "metadata": {
        "id": "rDvHoVGkT4gg"
      },
      "outputs": [],
      "source": [
        "n_components, pca_color = dim_red(color_vect)\n",
        "print(f'pca_color.shape: {pca_color.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_2_reduced.shape"
      ],
      "metadata": {
        "id": "brWz-QHlfUAw"
      },
      "id": "brWz-QHlfUAw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_2_reduced.info()"
      ],
      "metadata": {
        "id": "76UBMUtQgMUo"
      },
      "id": "76UBMUtQgMUo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_2_reduced.values[0:2, 9:10]"
      ],
      "metadata": {
        "id": "lXJc_f52gVHI"
      },
      "id": "lXJc_f52gVHI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_two_weeks(df):\n",
        "\n",
        "  \"\"\" As per product recommendation request in the next seven days following the most recent date in dataset,\n",
        "  we will reduce dataset period to the last two weeks\"\"\"\n",
        "\n",
        "  \"\"\"doing so, we have most recent article purchases made by customers\"\"\"\n",
        "\n",
        "  start_date = df['t_dat'].max() - pd.Timedelta(days=2 * 7)\n",
        "  end_date = df['t_dat'].max()\n",
        "  new_df = df[(df['t_dat'] >= start_date) & (df['t_dat'] <= end_date)]\n",
        "  print(f'new_df.shape: {new_df.shape}')\n",
        "\n",
        "  \"\"\"after reducing time period, we are going to\n",
        "  drop duplicates if article_id is the same\"\"\"\n",
        "  new_df = new_df.drop_duplicates(subset=['article_id'])\n",
        "  print(f'new_df.shape: {new_df.shape}')\n",
        "  print(f'new_df[0:2] -- {new_df[0:2]}')\n",
        "\n",
        "  return new_df\n"
      ],
      "metadata": {
        "id": "pccjvlT_SS74"
      },
      "id": "pccjvlT_SS74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = last_two_weeks(df_cleaned_2_reduced)\n",
        "df_3.shape"
      ],
      "metadata": {
        "id": "-T69antAWCo9"
      },
      "id": "-T69antAWCo9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from previous step, we see pca results have different dimensions\n",
        "to be able to concatenate those results, we have to get these same dimensions.\n",
        "this is the objective with this function.\n",
        "\"\"\"\n",
        "\n",
        "def retrieve_item(df):\n",
        "\n",
        "  \"\"\"l is a list of unique text items, seen in previous step, been embedded\"\"\"\n",
        "  features = ['detail_desc', 'garment_group_name', 'colour_group_name']\n",
        "\n",
        "  \"\"\"pca_mat results from text list embedding\"\"\"\n",
        "  pca_mat = [pca_detail_desc, pca_garment, pca_color]\n",
        "\n",
        "  \"\"\"list_of_arrays is used to append outputed arrays\"\"\"\n",
        "  list_of_arrays = []\n",
        "\n",
        "  for feature in features:\n",
        "    print(f'feature {feature}')\n",
        "\n",
        "    \"\"\"get mapping between embeddings and text items in dataframe\"\"\"\n",
        "    l = df[feature].unique().tolist()\n",
        "\n",
        "    idx_in_features = features.index(feature)\n",
        "\n",
        "    arr = df[[feature]].values\n",
        "\n",
        "    \"\"\"create array with same dims than arr, will store embeddings\"\"\"\n",
        "    new_arr = np.zeros((arr.shape[0], n_components))\n",
        "\n",
        "    for item in l:\n",
        "      idx_in_l = l.index(item)\n",
        "\n",
        "      \"\"\"get index of item in arr\n",
        "      np.where() function outputs two indices arrays:\n",
        "      one for rows + one for column\"\"\"\n",
        "\n",
        "      idx = np.where(arr == item)[0] # take only related rows indices array!\n",
        "      new_arr[idx] = pca_mat[idx_in_features][idx_in_l, :]\n",
        "\n",
        "    list_of_arrays.append(new_arr)\n",
        "  final_array = np.stack(list_of_arrays, axis=1)\n",
        "  print(f'final_array.shape: {final_array.shape}')\n",
        "\n",
        "  return final_array\n"
      ],
      "metadata": {
        "id": "f-L8mv9ZdlJQ"
      },
      "id": "f-L8mv9ZdlJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_array = retrieve_item(df_3)"
      ],
      "metadata": {
        "id": "XzVzP4lcdk78"
      },
      "id": "XzVzP4lcdk78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_array[0:2, :, :]"
      ],
      "metadata": {
        "id": "YUpFeNAp8HDK"
      },
      "id": "YUpFeNAp8HDK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "rXC9ZJgGcLtX",
      "metadata": {
        "id": "rXC9ZJgGcLtX"
      },
      "source": [
        "# Cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V3R_uRkucYW6",
      "metadata": {
        "id": "V3R_uRkucYW6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def reduce_dim(df, mat, nb_batches=100):\n",
        "  \"\"\"create article_id_temp array to be able to stack article_id with the array\n",
        "  that have different dimensions \"\"\"\n",
        "\n",
        "  article_id_temp = np.zeros((df.shape[0], 36))\n",
        "  article_id = df[['article_id']].values\n",
        "  article_id_temp[:, 0] = article_id[:, 0]\n",
        "\n",
        "  \"\"\"flatten the array: three features will be concatenated to produce one single pattern\"\"\"\n",
        "  new_mat = np.reshape(mat, (mat.shape[0], 3 * 12))\n",
        "  print(f'shape of mat after feature concatenating -- {new_mat.shape}')\n",
        "\n",
        "  \"\"\"stack article_id and new_mat\"\"\"\n",
        "  new_mat = np.stack([article_id_temp, new_mat], axis=1)\n",
        "  print(f'shape of mat after stacking article_id_temp -- {new_mat.shape}')\n",
        "  print()\n",
        "\n",
        "  cos_sim = cosine_similarity(new_mat[:, 1, :])\n",
        "  print(f'cos_sim.shape: {cos_sim.shape}')\n",
        "  print(f'cos_sim[0:2, :] -- {cos_sim[0:2, :]}')\n",
        "\n",
        "\n",
        "  return cos_sim, new_mat\n"
      ],
      "metadata": {
        "id": "77m8zaiUOWLb"
      },
      "id": "77m8zaiUOWLb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim, new_mat = reduce_dim(df_3, final_array)\n",
        "print(f'cos_sim.shape: {cos_sim.shape}, new_mat.shape: {new_mat.shape}')"
      ],
      "metadata": {
        "id": "9HY8uaomGzwf"
      },
      "id": "9HY8uaomGzwf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to retrieve best cosine similarity scores."
      ],
      "metadata": {
        "id": "af0Q4XRIjdMc"
      },
      "id": "af0Q4XRIjdMc"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"some article_id values\"\"\"\n",
        "some_art_id = list(df_3['article_id'][0:5])\n",
        "some_art_id"
      ],
      "metadata": {
        "id": "xC5RWsU5MQl-"
      },
      "id": "xC5RWsU5MQl-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_cos_sim(article_id, cos_sim, new_mat):\n",
        "  idx_article_id = np.where(new_mat[:, 0, :] == article_id)[0]\n",
        "  best_idx = np.argsort(cos_sim[idx_article_id])[0][-6:-1]\n",
        "  print(f'indices of ascending values -- {best_idx}')\n",
        "  print()\n",
        "\n",
        "  #print(f'article_id that correspond to indices -- {new_mat[best_idx, 0, :]}')\n",
        "  list_of_most_similar = [item[0].astype('int64') for item in new_mat[best_idx, 0, :]]\n",
        "  print(f'list_of_most_similar -- {list_of_most_similar}')\n",
        "  print('---')\n",
        "\n",
        "  \"\"\"display most similar articles\"\"\"\n",
        "  most_similar_articles = df_3[df_3['article_id'].isin(list_of_most_similar)]\n",
        "  d = {}\n",
        "  d[article_id] = list_of_most_similar\n",
        "  return most_similar_articles, d\n"
      ],
      "metadata": {
        "id": "oYUzKgVsjuFI"
      },
      "id": "oYUzKgVsjuFI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_most_similar, d_most_similar = get_best_cos_sim(some_art_id[1], cos_sim, new_mat)"
      ],
      "metadata": {
        "id": "AqdHO_KYjt4m"
      },
      "id": "AqdHO_KYjt4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'article_id input & most similar products: {d_most_similar}')"
      ],
      "metadata": {
        "id": "-D-ofQnfOJsV"
      },
      "id": "-D-ofQnfOJsV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3U1rGSef_0WS",
      "metadata": {
        "id": "3U1rGSef_0WS"
      },
      "outputs": [],
      "source": [
        "df_most_similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N-BTkk8w_0Oi",
      "metadata": {
        "id": "N-BTkk8w_0Oi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faHVr9ujtqfr",
      "metadata": {
        "id": "faHVr9ujtqfr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python_3.12",
      "language": "python",
      "name": "kernel_name"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}